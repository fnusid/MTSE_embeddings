LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name   | Type                 | Params | Mode
--------------------------------------------------------
0 | model  | RecursiveAttnPooling | 6.6 M  | train
1 | loss   | LossWrapper          | 0      | train
2 | metric | MetricsWrapper       | 0      | train
--------------------------------------------------------
6.6 M     Trainable params
0         Non-trainable params
6.6 M     Total params
26.599    Total estimated model params size (MB)
117       Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                                                                             | 0/2 [00:00<?, ?it/s]> /gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/recursive_attn_pooling.py(101)forward()
/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.
  warnings.warn(
/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release.
  s = torchaudio.io.StreamReader(src, format, None, buffer_size)
-> h = self.encoder(x, aug=False)  # [B, D, T]
Traceback (most recent call last):
  File "/gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/trainer.py", line 87, in <module>
    trainer.fit(model, dm)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run_stage
    self._run_sanity_check()
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1082, in _run_sanity_check
    val_loop.run()
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/trainer.py", line 46, in validation_step
    emb, p = self(noisy)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/trainer.py", line 31, in forward
    emb, p = self.model(x)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/recursive_attn_pooling.py", line 101, in forward
    h = self.encoder(x, aug=False)  # [B, D, T]
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/ECAPA_TDNN.py", line 169, in forward
    x = self.torchfbank(x)+1e-6
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/accounts/profdj_root/profdj0/sidcs/codebase/speaker_embedding_codebase/ECAPA_TDNN.py", line 93, in forward
    input = F.pad(input, (1, 0), 'reflect')
  File "/scratch/profdj_root/profdj0/sidcs/envs/miniconda3/envs/mtse/lib/python3.10/site-packages/torch/nn/functional.py", line 5290, in pad
    return torch._C._nn.pad(input, pad, mode, value)
NotImplementedError: Only 2D, 3D, 4D, 5D padding with non-constant padding are supported for now
